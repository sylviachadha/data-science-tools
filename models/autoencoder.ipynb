{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Autoencoder for dimension reduction\n",
    "# Reducing from high dimension data to low dimension data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "\n",
    "# Give size of encoded representation (usually kept low)\n",
    "encoding_dim = 1\n",
    "\n",
    "# Architecture of encoder - input, encoded & decoded layers\n",
    "input_img = keras.Input(shape=(784,))\n",
    "# ecodeded is encoded representation of input\n",
    "encoded = layers.Dense(encoding_dim, activation='relu')(input_img)\n",
    "# decoded is lossy reconstruction of input\n",
    "decoded = layers.Dense(784, activation='sigmoid')(encoded)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "outputs": [],
   "source": [
    "# Autoencoder model requires input_img & decoded representation\n",
    "# This model maps an input to its reconstruction\n",
    "autoencoder = keras.Model(input_img, decoded)\n",
    "\n",
    "# Encoder model requires input_img & encoded representation\n",
    "# This model maps an input to its encoded representation\n",
    "encoder = keras.Model(input_img, encoded)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "outputs": [],
   "source": [
    "# Decoder Model - requires encoded_input & decoder_layer\n",
    "\n",
    "# This is encoded 32 dimensional i/p\n",
    "encoded_input = keras.Input(shape=(encoding_dim))\n",
    "# Retrieve last layer of autoencoder model\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "# Create decoder model\n",
    "decoder = keras.Model(encoded_input, decoder_layer(encoded_input))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "# This is classification problem, so loss function-binary/categorical crossentropy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "outputs": [],
   "source": [
    "# Load data\n",
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "(x_train, _),(x_test, _) = mnist.load_data()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "outputs": [
    {
     "data": {
      "text/plain": "(60000, 28, 28)"
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "outputs": [
    {
     "data": {
      "text/plain": "(10000, 28, 28)"
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "# RGB is 0 to 255\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "\n",
    "# Convert to format that can be passed to encoder\n",
    "x_train = x_train.reshape(len(x_train),np.prod(x_train.shape[1:]))\n",
    "x_test = x_test.reshape((len(x_test),np.prod(x_test.shape[1:])))\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.4498 - val_loss: 0.2889\n",
      "Epoch 2/10\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2803 - val_loss: 0.2733\n",
      "Epoch 3/10\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.2710 - val_loss: 0.2679\n",
      "Epoch 4/10\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.2669 - val_loss: 0.2650\n",
      "Epoch 5/10\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2644 - val_loss: 0.2631\n",
      "Epoch 6/10\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2626 - val_loss: 0.2615\n",
      "Epoch 7/10\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.2613 - val_loss: 0.2605\n",
      "Epoch 8/10\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.2602 - val_loss: 0.2596\n",
      "Epoch 9/10\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2594 - val_loss: 0.2588\n",
      "Epoch 10/10\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2587 - val_loss: 0.2581\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x1d596ade8e0>"
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.fit(x_train,x_train,\n",
    "                epochs=10,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test,x_test))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "outputs": [],
   "source": [
    "# Encode & decode some mnist digits from test set\n",
    "encoded_imgs = encoder.predict(x_test)\n",
    "decoded_imgs = decoder.predict(encoded_imgs)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "outputs": [
    {
     "data": {
      "text/plain": "(10000, 1)"
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_imgs.shape\n",
    "# Earlier x_test (10000,784), 784 features, now entire image encoded into single feature"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[19.759195],\n       [12.818338],\n       [17.284964],\n       ...,\n       [37.238297],\n       [25.820982],\n       [23.522045]], dtype=float32)"
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_imgs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "outputs": [
    {
     "data": {
      "text/plain": "(10000, 784)"
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_imgs.shape\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "outputs": [
    {
     "data": {
      "text/plain": "(10000, 784)"
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape\n",
    "# Input x_test and decoded o/p same (10000,784)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "outputs": [],
   "source": [
    "# Dataset 2 for Autoencoder\n",
    "# we take another dataset created with random no & having high dimension\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(np.random.randint(0,100,size=(100,10)), columns=list('ABCDEFGHIJ'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "outputs": [
    {
     "data": {
      "text/plain": "     A   B   C   D   E   F   G   H   I   J\n0    7  35  61  33  59   0  82  42  91  83\n1   41  73  10  24  99   3  94  37  36  72\n2   68  12  60  45  98  14  31  42  79  11\n3   53  54  67  90  41  32  58  78  75  73\n4   73  55  25  64  45  81  47  51  27  59\n..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..\n95  22  73   5  13  78  83  39  93  41  89\n96  43  63  35  13  76  72  13  10  10  73\n97  33  60   3  91   5  34  40  17  53  36\n98  85  55  52  11  96   5  38  25  67  72\n99   7  14  43  76  61  27  65  66  67  32\n\n[100 rows x 10 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>A</th>\n      <th>B</th>\n      <th>C</th>\n      <th>D</th>\n      <th>E</th>\n      <th>F</th>\n      <th>G</th>\n      <th>H</th>\n      <th>I</th>\n      <th>J</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>7</td>\n      <td>35</td>\n      <td>61</td>\n      <td>33</td>\n      <td>59</td>\n      <td>0</td>\n      <td>82</td>\n      <td>42</td>\n      <td>91</td>\n      <td>83</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>41</td>\n      <td>73</td>\n      <td>10</td>\n      <td>24</td>\n      <td>99</td>\n      <td>3</td>\n      <td>94</td>\n      <td>37</td>\n      <td>36</td>\n      <td>72</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>68</td>\n      <td>12</td>\n      <td>60</td>\n      <td>45</td>\n      <td>98</td>\n      <td>14</td>\n      <td>31</td>\n      <td>42</td>\n      <td>79</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>53</td>\n      <td>54</td>\n      <td>67</td>\n      <td>90</td>\n      <td>41</td>\n      <td>32</td>\n      <td>58</td>\n      <td>78</td>\n      <td>75</td>\n      <td>73</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>73</td>\n      <td>55</td>\n      <td>25</td>\n      <td>64</td>\n      <td>45</td>\n      <td>81</td>\n      <td>47</td>\n      <td>51</td>\n      <td>27</td>\n      <td>59</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>22</td>\n      <td>73</td>\n      <td>5</td>\n      <td>13</td>\n      <td>78</td>\n      <td>83</td>\n      <td>39</td>\n      <td>93</td>\n      <td>41</td>\n      <td>89</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>43</td>\n      <td>63</td>\n      <td>35</td>\n      <td>13</td>\n      <td>76</td>\n      <td>72</td>\n      <td>13</td>\n      <td>10</td>\n      <td>10</td>\n      <td>73</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>33</td>\n      <td>60</td>\n      <td>3</td>\n      <td>91</td>\n      <td>5</td>\n      <td>34</td>\n      <td>40</td>\n      <td>17</td>\n      <td>53</td>\n      <td>36</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>85</td>\n      <td>55</td>\n      <td>52</td>\n      <td>11</td>\n      <td>96</td>\n      <td>5</td>\n      <td>38</td>\n      <td>25</td>\n      <td>67</td>\n      <td>72</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>7</td>\n      <td>14</td>\n      <td>43</td>\n      <td>76</td>\n      <td>61</td>\n      <td>27</td>\n      <td>65</td>\n      <td>66</td>\n      <td>67</td>\n      <td>32</td>\n    </tr>\n  </tbody>\n</table>\n<p>100 rows × 10 columns</p>\n</div>"
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "outputs": [],
   "source": [
    "# Divide data into train & test and change to array cz encoder\n",
    "# decoder model takes array.\n",
    "\n",
    "x_train = df[:70]\n",
    "x_test = df[70:]\n",
    "x_train = np.array(x_train)\n",
    "x_test = np.array(x_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70, 10)\n",
      "(30, 10)\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train = x_train.reshape((len(x_train),np.prod(x_train.shape[1:])))\n",
    "x_test = x_test.reshape((len(x_test),np.prod(x_test.shape[1:])))\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "outputs": [],
   "source": [
    "# This is size of encoded representation\n",
    "encoding_dim = 2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "outputs": [],
   "source": [
    "# This is i/p image - original i/p\n",
    "input_img = keras.Input(shape=(10,))\n",
    "# encoded is encoded representation of input\n",
    "encoded = layers.Dense(encoding_dim, activation='relu')(input_img)\n",
    "# decoded is lossy reconstruction of input\n",
    "decoded = layers.Dense(10, activation='sigmoid')(encoded)\n",
    "\n",
    "# This model maps an input to its reconstruction\n",
    "autoencoder = keras.Model(input_img, decoded)\n",
    "# THis model maps an input to its encoded representation\n",
    "encoder = keras.Model(input_img, encoded)\n",
    "\n",
    "# This is encoded input\n",
    "encoded_input = keras.Input(shape=(encoding_dim))\n",
    "# Retrieve last layer of autoencoder model\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "# Create decoder model\n",
    "decoder = keras.Model(encoded_input, decoder_layer(encoded_input))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "outputs": [],
   "source": [
    "# Compile model\n",
    "autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# loss=mae cz numerical data not doing classifications"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "outputs": [
    {
     "data": {
      "text/plain": "[<keras.engine.input_layer.InputLayer at 0x1d596c5a0d0>,\n <keras.layers.core.dense.Dense at 0x1d596c5a070>,\n <keras.layers.core.dense.Dense at 0x1d596c5ae80>]"
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.layers"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 317ms/step - loss: 0.1057 - val_loss: 0.1070\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.1055 - val_loss: 0.1068\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.1053 - val_loss: 0.1066\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.1050 - val_loss: 0.1063\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.1048 - val_loss: 0.1061\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1046 - val_loss: 0.1058\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.1043 - val_loss: 0.1056\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.1041 - val_loss: 0.1053\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.1039 - val_loss: 0.1051\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.1036 - val_loss: 0.1049\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.1034 - val_loss: 0.1046\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.1031 - val_loss: 0.1044\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.1029 - val_loss: 0.1041\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.1026 - val_loss: 0.1039\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.1023 - val_loss: 0.1036\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.1021 - val_loss: 0.1034\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.1018 - val_loss: 0.1031\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.1016 - val_loss: 0.1029\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.1013 - val_loss: 0.1026\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.1011 - val_loss: 0.1023\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.1008 - val_loss: 0.1021\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.1005 - val_loss: 0.1018\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.1003 - val_loss: 0.1016\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.1000 - val_loss: 0.1013\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0997 - val_loss: 0.1010\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0995 - val_loss: 0.1008\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0992 - val_loss: 0.1005\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0989 - val_loss: 0.1002\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0986 - val_loss: 0.1000\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0984 - val_loss: 0.0997\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x1d596c8b310>"
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.fit(x_train,x_train,\n",
    "                epochs=30,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test,x_test))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "outputs": [],
   "source": [
    "# Predict\n",
    "\n",
    "encoded_output = encoder.predict(x_test)\n",
    "decoded_output = decoder.predict(encoded_output)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.00000000e+00, 1.01378247e-01],\n       [1.45520285e-01, 0.00000000e+00],\n       [1.19025886e-01, 0.00000000e+00],\n       [4.00316536e-01, 7.59410188e-02],\n       [1.92915127e-01, 0.00000000e+00],\n       [1.56247035e-01, 0.00000000e+00],\n       [1.32757291e-01, 0.00000000e+00],\n       [2.28838935e-01, 0.00000000e+00],\n       [0.00000000e+00, 0.00000000e+00],\n       [2.24780872e-01, 2.90970691e-02],\n       [4.23416525e-01, 1.54413283e-05],\n       [4.66322601e-01, 1.70776144e-01],\n       [1.69699863e-01, 1.24023005e-01],\n       [9.06121582e-02, 0.00000000e+00],\n       [2.29554981e-01, 0.00000000e+00],\n       [2.17585459e-01, 1.28843024e-01],\n       [2.44167820e-02, 0.00000000e+00],\n       [0.00000000e+00, 0.00000000e+00],\n       [2.01117992e-01, 0.00000000e+00],\n       [1.83853269e-01, 1.27583053e-02],\n       [5.87681048e-02, 0.00000000e+00],\n       [1.74434841e-01, 0.00000000e+00],\n       [2.84673840e-01, 2.07646668e-01],\n       [3.86228263e-01, 2.50456184e-01],\n       [2.23563761e-02, 2.26397112e-01],\n       [3.08172077e-01, 1.76166028e-01],\n       [1.40092112e-02, 1.65884539e-01],\n       [1.86361566e-01, 5.69769479e-02],\n       [1.69388488e-01, 3.09929699e-01],\n       [1.19614810e-01, 0.00000000e+00]], dtype=float32)"
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_output\n",
    "\n",
    "# Reduce 10 features into 2 features"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "outputs": [
    {
     "data": {
      "text/plain": "(30, 2)"
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_output.shape\n",
    "\n",
    "# 10 dimensions reduced to two dimensions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x432 with 2 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW8AAAFpCAYAAABTZakJAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAfIUlEQVR4nO3df4ydV3ng8e/D4MAsUIbWXqmexCS0xsKtK9wOSVfVQrsNtaFax0phcSq06TZdiy7Zdjet1VigUIWySRmJLavNtvHSqIUVpIFalqWanaUlbNVtTe3UNF4HzdZJA/G4EgmJaSWGYI+f/ePeMdfT+fHeX3Pvue/3I73KfX+de145fu7xc857TmQmkqSyvGTQFZAktc/gLUkFMnhLUoEM3pJUIIO3JBXI4C1JBTJ4S1IfRcRDEfG1iPi/K5yPiPgvEXE2Ih6PiB+uUq7BW5L66/eA3aucfxuwtbntB367SqEGb0nqo8z8U+D5VS65Bfh4NhwHJiLie9cq1+AtSYM1CTzTsn+ueWxVL+1bdTq0cePGvP766wddDUkFeOyxx57LzE3dlLHrJ16RX39+ofM6PP7iGeBbLYcOZeahbupUxdAF7+uvv56TJ08OuhqSChARX+m2jOeeX+CLM9d2fP+G733yW5k51UUV5oDrWvavbR5blWkTSTWXLOTljrceOAr86+aokx8FvpGZf7fWTUPX8pak9ZTAZfo3u2pEfAr4cWBjRJwDPgBsAMjM3wGOAW8HzgLfBP5NlXIN3pLUR5l52xrnE3hvu+UavCXV3mV6kv5YVwZvSbWWJAsFLkpj8JZUe/3MefeLo00kqUC2vCXVWgILBba8Dd6Saq/EtInBWys6cmqO6ZlZzl+YZ/PEOAd2bWPvzjWnXJCKkmCHpUbHkVNzHDx8mvmLjTkf5i7Mc/DwaQADuEZOeQMF7bDUCqZnZq8E7kXzFxeYnpkdUI0ktbLlrWWdvzDf1nGpVEnaYanRsXlinLllAvXmifEB1Ebqo4SF8mK3aRMt78CubYxvGLvq2PiGMQ7s2jagGkn90ZiYqvNtUGx5a1mLnZKONtHoCxaIQVeibQZvrWjvzkmDtTSkDN6Sai2BywXmvA3ekmqvxLRJpQ7LiNgdEbMRcTYi7l7m/Hsi4nREfCki/iwitrecO9i8bzYidvWy8pLUrcbcJtHxNihrBu+IGAMeAN4GbAduaw3OTZ/MzB2Z+Ubgw8BHmvduB/YBPwDsBv5bszxJUheqtLxvBM5m5lOZ+W3gYeCW1gsy8+9bdl8BV0a83wI8nJkvZubf0lij7cbuqy1JvXM5o+NtUKrkvCeBZ1r2zwE3Lb0oIt4L3AVcA/yLlnuPL7n3Hw1fiIj9wH6ALVu2VKm3JPXEYtqkND17SSczH8jM7wN+DXh/m/ceysypzJzatGlTr6okSWtKggVe0vE2KFVa3nPAdS371zaPreRh4Lc7vFeS1t0g0x+dqvKzcQLYGhE3RMQ1NDogj7ZeEBFbW3Z/Gvib5uejwL6IeFlE3ABsBf6y+2pLUr2t2fLOzEsRcScwA4wBD2XmmYi4FziZmUeBOyPiZuAi8AJwe/PeMxHxCPAEcAl4b2YuLPtFkjQApea8K72kk5nHgGNLjt3T8vmXV7n3Q8CHOq2gJPVXsJDlzdHnG5aSaq0xq6DBW5KKU2LapLyfG0mSLW9J9ZZpzluSinS5wLSJwVtSrTWGCpbX8i6vxpIkW96S6s6ctyQVx3HeklSohQInpjJ4S6q1xSlhS1NejSVJtrwl6bIdlpJUllLHeRu8JdVaEkV2WJb3cyNJsuUtSY7zlqTCZOIblpJUnnBWQUkqTVJmy7u8GkuSbHlLkuO8JakwSXC5wHHeBm9JtWfLW5IKk5Q5t0l5NZYk2fKWVHfBguO8JakspaZNDN6Saq/Elnd5PzeSJFvekuotM4pMm5RXY0nqsYV8ScdbFRGxOyJmI+JsRNy9zPktEfFoRJyKiMcj4u1rlWnLW1KtJfR1VsGIGAMeAN4KnANORMTRzHyi5bL3A49k5m9HxHbgGHD9auUavCXVXPR7VsEbgbOZ+RRARDwM3AK0Bu8Evqv5+dXA+bUKNXhLUn9NAs+07J8Dblpyza8D/ysi/j3wCuDmtQo15y2p1hrjvKPjDdgYESdbtv0dVOM24Pcy81rg7cAnImLV+GzLW1LtdTkx1XOZObXK+Tngupb9a5vHWt0B7AbIzL+IiJcDG4GvrVSoLW9JtbY4JWwXLe+1nAC2RsQNEXENsA84uuSarwI/CRARbwBeDjy7WqGVWt4RsRv4KDAGfCwz719y/i7gF4BLzS/8+cz8SvPcAnB6sYKZuafKd0rq3pFTc0zPzHL+wjybJ8Y5sGsbe3dODrpaQ6efq8dn5qWIuBOYoRFDH8rMMxFxL3AyM48CvwL894j4jzQyOT+XmblauWsG74rDXE4BU5n5zYj4ReDDwLua5+Yz843tPKyk7h05NcfBw6eZv7gAwNyFeQ4ebrSjDODrKzOP0Rj+13rsnpbPTwA/1k6ZVX5urgxzycxvA4vDXFor8WhmfrO5e5xGTkfSAE3PzF4J3IvmLy4wPTM7oBoNp0xYyOh4G5QqwXu5YS6r/WzfAXy2Zf/lzR7Y4xGxt/0qSurE+QvzbR2vsz7nvPuip6NNIuLdwBTwlpbDr83MuYh4HfD5iDidmU8uuW8/sB9gy5YtvaySVFubJ8aZWyZQb54YH0Bthlejw7K8sRtValxlmAsRcTPwPmBPZr64eDwz55r/fQr4ArBz6b2ZeSgzpzJzatOmTW09gKTlHdi1jfENY1cdG98wxoFd2wZUI/VSleC95jCXiNgJPEgjcH+t5fhrIuJlzc8baSTkWzs6JfXJ3p2T3HfrDiYnxglgcmKc+27dYWflMhaaq+l0sg3KmmmTisNcpoFXAp+OCPjOkMA3AA9GxGUaPxT3LxmlIqmP9u6cNFivYfENy9JUynlXGOay7Hv4mfnnwI5uKihJ/VVmztvX4yXVXj+nhO2X8n5uJEm2vCXV2+JLOqUxeEuqPXPeklSYxVkFS2PwllR7dlhKktaFLW9JtTbSL+lI0iizw1KSSjPgqV07Vd7PjSTJlrekekvKHG1i8JZUeyWmTQzekmrN0SZD7sipOaZnZjl/YZ7NE+Mc2LXNeY4lAQbvoXXk1BwHD5++spL23IV5Dh4+DWAAl1SkWow2mZ6ZvRK4F81fXGB6ZnZANZI0LBbnNqn16vHD6vwyK2ivdlxSvTjaZEhtnhhnbplAvXlifAC1kTRUssycdy3SJgd2bWN8w9hVx8Y3jHFg17YB1UjSsFgcbWLaZAgtdko62kTSqKhF8IZGADdYS1pOiWmT2gRvSVqOK+lIUqGywOBdiw5LSRo1trwl1Z7jvCWpMFnoOG+Dt6TaKzHnbfCWVHNljjaxw1KSCmTLW1LtmTaRpMK4ko5UOFdbqqlsjDgpjcFbwtWW6q7Ecd52WEq42pLKY8tbwtWW6iyxw1Iqlqst1ZnjvKViudpSvWV2vg2KLW8JV1tSeSoF74jYDXwUGAM+lpn3Lzl/F/ALwCXgWeDnM/MrzXO3A+9vXvobmfn7Paq71FOutlRfJea810ybRMQY8ADwNmA7cFtEbF9y2SlgKjN/CPgM8OHmvd8NfAC4CbgR+EBEvKZ31Zek7jTSH9HxNihVct43Amcz86nM/DbwMHBL6wWZ+WhmfrO5exy4tvl5F/C5zHw+M18APgfs7k3VJak3Slw9vkrwngSeadk/1zy2kjuAz3Z4ryStu9p3WEbEu4Ep4C1t3rcf2A+wZcuWXlZJkkZSlZb3HHBdy/61zWNXiYibgfcBezLzxXbuzcxDmTmVmVObNm2qWndJ6olRzXmfALZGxA0RcQ2wDzjaekFE7AQepBG4v9Zyagb4qYh4TbOj8qeaxyRpKCSdB+5BBu810yaZeSki7qQRdMeAhzLzTETcC5zMzKPANPBK4NMRAfDVzNyTmc9HxAdp/AAA3JuZz/flSSSpQwVOKlgt552Zx4BjS47d0/L55lXufQh4qNMKSlJf5YiO85YkDR9fj5ekAvMmtrwl1V6/OywjYndEzEbE2Yi4e4Vr/lVEPBERZyLik2uVactbUu3182WblilG3krjRcUTEXE0M59ouWYrcBD4scx8ISL+6Vrl2vKWpP5ac4oR4N8CDzSnEWHJkOtlGbwl1driSjpdpE02RsTJlm3/kq+oMk3I64HXR8T/iYjjzZlcV2XaRFK9JdDdUMHnMnOqy1q8FNgK/DiNN9H/NCJ2ZOaFlW6w5S2p9vo8MVWVaULOAUcz82Jm/i3w/2gE8xUZvCUpu9jWtuYUI8ARGq1uImIjjTTKU6sVavCWpD7KzEvA4hQjXwYeWZxiJCL2NC+bAb4eEU8AjwIHMvPrq5VrzltSzfV/gqkKU4wkcFdzq8TgLUkFvmFp8JZUb05MJUlaL7a8pS4cOTXH9Mws5y/Ms3linAO7trF3p8u0Fse0iVQfR07NcfDwaeYvLgAwd2Geg4dPAxjAi2PaRKqN6ZnZK4F70fzFBaZnZgdUI3Wsv+O8+8KWt9Sh8xfm2zquIVZg2sSWt9ShzRPjbR2XesngLXXowK5tjG8Yu+rY+IYxDuzaNqAaqSOLE1N1ug2IaROpQ4udko426d6gR+30czGGfjF4S13Yu3PSYN2loRi1U2DwNm0iaaCGYtROgWkTg7ekgXLUTmdGNm0y6ByapGo2T4wzt0ygXs9RO2HaZDgs5tDmLsyTfCeHduTU0sUrJA3awEftdPOCzgCD/kgG76HIoUmqZO/OSe67dQeTE+MEMDkxzn237ljHfyl3ke92qGBvmUOTyuKonfaNZMvbN98ktcW0yXAYeA5NUlkKDN4jmTbxzTdJbSlwtMlIBm8whyaposW5TQozkmkTSRp1I9vylqSqSnxJx+AtSQUGb9MmklQgW96Saq/EtIktb0kqkC1vSRrVoYIRsTsiZiPibETcvcz5N0fEX0XEpYh4x5JzCxHxpeZ2tFcVl6SeKHRWwTVb3hExBjwAvBU4B5yIiKOZ+UTLZV8Ffg741WWKmM/MN3ZfVUnqkwJz3lXSJjcCZzPzKYCIeBi4BbgSvDPz6ea5y32ooyRpiSppk0ngmZb9c81jVb08Ik5GxPGI2LvcBRGxv3nNyWeffbaNoiWpe5Gdb4OyHh2Wr83MuYh4HfD5iDidmU+2XpCZh4BDAFNTUwX+A0ZS0QqMOlVa3nPAdS371zaPVZKZc83/PgV8AdjZRv0kqf8K7LCsErxPAFsj4oaIuAbYB1QaNRIRr4mIlzU/bwR+jJZcuSQNWjcpk0GmTdYM3pl5CbgTmAG+DDySmWci4t6I2AMQEW+KiHPAO4EHI+JM8/Y3ACcj4q+BR4H7l4xSkSR1oFLOOzOPAceWHLun5fMJGumUpff9ObCjyzpKUn8V+JKOb1hKUoEdlgZvSbVX4sRUBm9JKjB4O6ugJBXIlrekehvwkL9OGbwlyeAtSQUqMHib85akAtnyllR7Jea8bXlLUoFseUtSgS1vg7ekenOooNS+I6fmmJ6Z5fyFeTZPjHNg1zb27mxnoSapngzeGpgjp+Y4ePg08xcXAJi7MM/Bw6cBDOBaXwW2vO2w1MBMz8xeCdyL5i8uMD0zO6AaqbYKXEnHlrcG5vyF+baOS/0QmPPWiOl3PnrzxDhzywTqzRPjPfsOqZICg7dpEy1rMR89d2Ge5Dv56COnKq89vaYDu7YxvmHsqmPjG8Y4sGtbz75DGlUGby1rPfLRe3dOct+tO5icGCeAyYlx7rt1h52VWl+FLkBs2kTLWq989N6dkwZrDV6fg3BE7AY+CowBH8vM+1e47meAzwBvysyTq5Vpy1vLWinvbD5aI6mPo00iYgx4AHgbsB24LSK2L3Pdq4BfBr5YpcoGby3LfLTUMzcCZzPzqcz8NvAwcMsy130Q+E3gW1UKNXhrWeajVSdd5rw3RsTJlm3/kuIngWda9s81j33n+yN+GLguM/+oap3NeWtF5qNVG93lvJ/LzKlOb46IlwAfAX6unftseUuqt27y3dWC/hxwXcv+tc1ji14F/CDwhYh4GvhR4GhErPqDYMtbUu31ecjfCWBrRNxAI2jvA3528WRmfgPYeKUuEV8AftXRJpI0QJl5CbgTmAG+DDySmWci4t6I2NNpuba8JanP47wz8xhwbMmxe1a49serlGnwllR7TkwlSSUyeEtSYQY8L3en7LCUpALZ8pZUa9HcSmPwlqQC0yYGb0m1V+JoE3PeklQgW96SVGDL2+AtSQbv9dXv1c0l1cCA16LsVKWcd0TsjojZiDgbEXcvc/7NEfFXEXEpIt6x5NztEfE3ze32XlV8PVY3l1QT/Z0Sti/WDN4V11/7Ko2JxD+55N7vBj4A3ERjKaAPRMRruq/2+qxuLknDqkrLe8311zLz6cx8HLi85N5dwOcy8/nMfAH4HLC7B/Vet9XNJY2+LpdBG4gqwXvN9de6vTci9i+u//bss89WKtjVzSX1zCimTdZDZh7KzKnMnNq0aVOle1zdXFKvjGrLe6311/p176pc3VxSnVUZKrjq+mtrmAH+U0sn5U8BB9uu5Qpc3VxS10Z1Stgq669FxJsi4hzwTuDBiDjTvPd54IM0fgBOAPc2j0nS8Cgw513pJZ211l/LzBM0UiLL3fsQ8FAXdZSkvgnKfEmn6DcsJaknCgzeQzHaRJLUHlvekmovsrymt8FbUr0VOtrE4C2p9uywlKQSFRi87bCUpALZ8pZUe6ZNJKlEBm9JKswoL4MmSRoutrwlqcCWt8FbUq05MZUklcrX4yWV5MipOaZnZjl/YZ7NE+Mc2LWtlguc2PKWVIwjp+Y4ePg08xcXAJi7MM/Bw6cBahnAS+NoE6mmpmdmrwTuRfMXF5iemR1QjQakm1V0hn0lHUmj5/yF+baOj7K4POgatM+Wt1RTmyfG2zo+0gpseRu8pZo6sGsb4xvGrjo2vmGMA7u2DahGgxPZ+TYopk2kmlrslHS0SZkM3lKN7d05abBOHOctSSVynLcklajA4G2HpSQVyJa3pFpzYipJKlGmHZaSVCJb3pJUogKDtx2WklQgW96Sas+0iSSVJoHL5UVvg7e64kosGgnlxW6DtzrnSiwaFSWmTeywVMdciUUaHFve6pgrsWhkFPiSji1vdcyVWDQq+r0YQ0TsjojZiDgbEXcvc/6uiHgiIh6PiD+JiNeuVabBWx1zJRaNhD4vQBwRY8ADwNuA7cBtEbF9yWWngKnM/CHgM8CH1yrX4K2O7d05yX237mByYpwAJifGue/WHXZWSle7ETibmU9l5reBh4FbWi/IzEcz85vN3ePAtWsVWinnHRG7gY8CY8DHMvP+JedfBnwc+BHg68C7MvPpiLge+DKw2IN1PDPfU+U7VQZXYlHpGrMK9jXnPQk807J/DrhplevvAD67VqFrBu+WJv9bm196IiKOZuYTS77shcz8/ojYB/wm8K7muScz841rfY8kDczlru7eGBEnW/YPZeahTgqKiHcDU8Bb1rq2Ssv7SpO/Wfhik781eN8C/Hrz82eA/xoR0UadJWlgumx5P5eZU6ucnwOua9m/tnns6jpE3Ay8D3hLZr641pdWyXkv1+Rf+u/kK9dk5iXgG8D3NM/dEBGnIuJ/R8Q/X+4LImJ/RJyMiJPPPvtshSpJUo/0ucMSOAFsjYgbIuIaYB9wtPWCiNgJPAjsycyvVSm03x2WfwdsycydwF3AJyPiu5ZelJmHMnMqM6c2bdrU5ypJ0vppNmjvBGZo9AE+kplnIuLeiNjTvGwaeCXw6Yj4UkQcXaG4K6qkTao0+RevORcRLwVeDXw9MxN4sfkAj0XEk8DrgZNI0lDo/0o6mXkMOLbk2D0tn29ut8wqLe81m/zN/dubn98BfD4zMyI2NTs8iYjXAVuBp9qtpCT1U79f0umHNVvemXkpIhab/GPAQ4tNfuBkZh4Ffhf4REScBZ6nEeAB3gzcGxEXafTnviczn+/Hg0hSxwp8Pb7SOO8KTf5vAe9c5r4/BP6wyzpKUv8kRHdDBQfCNywlqUDOKihJo5o2kaSRVl7sNnhLUp/nNukLc96SVCBb3pJUYMvb4C2p3pJuZxUcCIO3pFoLssict8FbkgoM3nZYSlKBbHlLUoEtb4O3hsqRU3NMz8xy/sI8myfGObBrm2tkqr/ssJS6c+TUHAcPn2b+4gIAcxfmOXj4NIABXH1VYoelOW8NjemZ2SuBe9H8xQWmZ2YHVCPVRmbn24AYvDU0zl+Yb+u4VGcGbw2NzRPjbR2XeqOLVrctbwkO7NrG+Iaxq46NbxjjwK5tA6qRaiEpMnjbYamhsdgp6WgTrTtHm0jd2btz0mAtVWDwllR7JQ4VNHhLksFbkgqTwGWDtyQVZrCjRjrlUEFJKpAtb0kqsOVt8JYkg7ckFcYOS9WNc29rNCRkea9YGrzVEefelgbL0SbqiHNva6Q4MZXqwrm3NTIKzXnb8lZHnHtbI6XAlrfBWx1x7m1psEybqCPOva2R4jhv1Ylzb2s0lDm3icFbUr0lcNlx3pJUngJb3nZYSlKBbHlLUoEt70rBOyJ2Ax8FxoCPZeb9S86/DPg48CPA14F3ZebTzXMHgTuABeCXMnOmV5V//5HTfOqLz7CQyVgEt910Hb+xd8eK1/dqLo5elNNNGas992rlLncOqo0YqVLfbspv5xk1OKM5n00W+ZLOmsE7IsaAB4C3AueAExFxNDOfaLnsDuCFzPz+iNgH/CbwrojYDuwDfgDYDPxxRLw+M69+r7oD7z9ymv9x/KtX9hcyr+wv95e8V3Nx9KKcbspY7bmnXvvdK5YL/KNzBz791xBwcSFXrUeV+i53TdXy23lGA/jgjOx8NglZ4MRUVXLeNwJnM/OpzPw28DBwy5JrbgF+v/n5M8BPRkQ0jz+cmS9m5t8CZ5vlde1TX3ymreO9moujF+V0U8Zqz71aucudu3g5rwTW1epRpb7dlL/cs7RzXOvD+WyGS5W0ySTQ+rfmHHDTStdk5qWI+AbwPc3jx5fc+49+oiNiP7AfYMuWLZUqvrBCjmql472ai6MX5XRTxmrP3a9nrFJuL55/Ubt/tlofIz2fTYFpk6EYbZKZhzJzKjOnNm3aVOmesYi2jvdqLo5elNNNGas992rldlO/KvXtxfMvavfPVutjpOezGdG5TeaA61r2r20eW/aaiHgp8GoaHZdV7u3IbTdd19bxXs3F0Ytyuiljtederdzlzm14SbBhLJa9vt36dlP+cs/SznGtj5Gdzyaz8ZJOp9uAVEmbnAC2RsQNNALvPuBnl1xzFLgd+AvgHcDnMzMj4ijwyYj4CI0Oy63AX/ai4osdV1VHJPRqLo5elNNNGVWee7VyOxkNUqW+K13TyXO2+2er9THS89kUmJKLrFDpiHg78Fs0hgo+lJkfioh7gZOZeTQiXg58AtgJPA/sy8ynmve+D/h54BLwHzLzs6t919TUVJ48ebKLR5JUFxHxWGZOdVPGq8c25j97xb/s+P6Zf/i9ruvQiUrjvDPzGHBsybF7Wj5/C3jnCvd+CPhQF3WUpL5K5zaRpNI4q6AklafQZdAM3pI0om9YSpKGjC1vSbWWQBaYNrHlLaneMhtpk063CiJid0TMRsTZiLh7mfMvi4g/aJ7/YkRcv1aZBm9JtZeXs+NtLS0zs74N2A7c1pxxtdWVmVmB/0xjZtZVGbwlqb+6mZl1RQZvSepv2mS5mVmXzilw1cyswOLMrCsaug7Lxx577LmI+Eqbt20EnutHfQbE5xluPs/weG23BfwDL8z8cX5mYxdFvDwiWuf0OJSZh7qt11qGLnhnZrU5YVtExMlBzC3QLz7PcPN5Rktm7u7zV7QzM+u5JTOzrsi0iST115WZWSPiGhozsx5dcs3izKzQMjPraoUOXctbkkZJc3WxO4EZvjMz65nWmVmB3wU+ERFnac7Mula5oxK8+55fWmc+z3DzedSWbmZmXUml+bwlScPFnLckFaiY4N2P10sHrcIzvTki/ioiLkXEOwZRx3ZUeJ67IuKJiHg8Iv4kIroe5tVPFZ7nPRFxOiK+FBF/tsxbc0Nlredpue5nIiIjorYjUIqQmUO/0UjyPwm8DrgG+Gtg+5Jr/h3wO83P+4A/GHS9e/BM1wM/BHwceMeg69yD5/kJ4J80P//iMP8ZVXye72r5vAf4n4OudzfP07zuVcCfAseBqUHX223lrZSWd19eLx2wNZ8pM5/OzMeBEiYbrvI8j2bmN5u7x2mMdx1WVZ7n71t2X0FjgrphVeXvEMAHacyr8a31rJzaV0rw7svrpQNW5ZlK0u7z3AGsuhj1gFV6noh4b0Q8CXwY+KV1qlsn1nyeiPhh4LrM/KP1rJg6U0rw1giJiHcDU8D0oOvSrcx8IDO/D/g14P2Drk+nIuIlwEeAXxl0XVRNKcG7nddLqfp66YBVeaaSVHqeiLgZeB+wJzNfXKe6daLdP5+Hgb39rFCX1nqeVwE/CHwhIp4GfhQ4aqfl8ColePfl9dIBq/JMJVnzeSJiJ/AgjcD9tQHUsR1Vnmdry+5PA3+zjvVr16rPk5nfyMyNmXl9Zl5Po09iT2aeXL44DVoRwbuZw158vfTLwCPZfL00IvY0L/td4Huar5feBaw4FGoYVHmmiHhTRJyj8ebVgxFxZnA1Xl3FP6Np4JXAp5vD64b2x6ri89wZEWci4ks0/p+7ffnSBq/i86ggvmEpSQUqouUtSbqawVuSCmTwlqQCGbwlqUAGb0kqkMFbkgpk8JakAhm8JalA/x//NjBxw3UAngAAAABJRU5ErkJggg==\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x_test_encoded = encoder.predict(x_test, batch_size=2)\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.scatter(x_test_encoded[:,0],x_test_encoded[:,1])\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "# Below encoded representation tells u that data is v random there is\n",
    "# no relationship b/w 2 variables/features & data was also here randomly generated"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0.        , 0.14552028, 0.1190259 , 0.40031654, 0.19291514,\n       0.15624702, 0.13275729, 0.22883895, 0.        , 0.22478086,\n       0.4234165 , 0.4663226 , 0.16969985, 0.09061216, 0.22955495,\n       0.21758544, 0.02441678, 0.        , 0.201118  , 0.18385325,\n       0.0587681 , 0.17443484, 0.28467387, 0.38622826, 0.02235637,\n       0.3081721 , 0.01400922, 0.18636157, 0.16938849, 0.11961479],\n      dtype=float32)"
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_encoded[:,0]  # 1st encoded feature"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "outputs": [
    {
     "data": {
      "text/plain": "array([1.01378247e-01, 0.00000000e+00, 0.00000000e+00, 7.59410113e-02,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 2.90971063e-02, 1.54487789e-05, 1.70776173e-01,\n       1.24023005e-01, 0.00000000e+00, 0.00000000e+00, 1.28843024e-01,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.27583109e-02,\n       0.00000000e+00, 0.00000000e+00, 2.07646668e-01, 2.50456184e-01,\n       2.26397112e-01, 1.76166013e-01, 1.65884539e-01, 5.69769405e-02,\n       3.09929699e-01, 0.00000000e+00], dtype=float32)"
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_encoded[:,1]  # 2nd encoded feature"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.48848706, 0.50134486, 0.47755793, 0.47474548, 0.49873298,\n        0.48665348, 0.48817286, 0.5056744 , 0.48210436, 0.47954112],\n       [0.46979654, 0.49690965, 0.46620044, 0.486589  , 0.47106102,\n        0.48446453, 0.51211905, 0.49997213, 0.46813175, 0.50608313],\n       [0.47393325, 0.49610797, 0.4709908 , 0.48767242, 0.4749664 ,\n        0.48593292, 0.5085482 , 0.49861175, 0.4725714 , 0.5036124 ],\n       [0.4273215 , 0.5112387 , 0.40964764, 0.46288243, 0.4383144 ,\n        0.46597287, 0.5431271 , 0.5229077 , 0.41814733, 0.52011114],\n       [0.4624072 , 0.49834377, 0.45764717, 0.48465133, 0.46408397,\n        0.4818385 , 0.5185036 , 0.50240564, 0.46020287, 0.5105021 ],\n       [0.46812284, 0.49723423, 0.46426266, 0.48615044, 0.46948084,\n        0.48387012, 0.51356447, 0.5005229 , 0.46633568, 0.5070834 ],\n       [0.47178882, 0.49652344, 0.46850735, 0.4871109 , 0.4729419 ,\n        0.48517185, 0.51039904, 0.4993168 , 0.47026986, 0.50489295],\n       [0.45681712, 0.4994308 , 0.4511804 , 0.4831829 , 0.4588048 ,\n        0.4798487 , 0.523339  , 0.5042501 , 0.4542062 , 0.5138505 ],\n       [0.4925535 , 0.49250677, 0.49256492, 0.4925408 , 0.49254224,\n        0.4925322 , 0.49250042, 0.49250078, 0.49255994, 0.49251226],\n       [0.4562892 , 0.5018448 , 0.44764227, 0.4782428 , 0.46116647,\n        0.47838834, 0.5215528 , 0.5078225 , 0.4519061 , 0.50974834],\n       [0.42676204, 0.5053198 , 0.41649115, 0.47523233, 0.4304015 ,\n        0.46908304, 0.54942966, 0.5142392 , 0.42199767, 0.5319555 ],\n       [0.4135366 , 0.52149284, 0.38472104, 0.44368672, 0.4344123 ,\n        0.45686457, 0.54793715, 0.53856033, 0.39796972, 0.51413006],\n       [0.46107474, 0.5084534 , 0.44362345, 0.46386364, 0.47504902,\n        0.47594184, 0.51008415, 0.517324  , 0.45137686, 0.4924573 ],\n       [0.47837362, 0.49524823, 0.47613415, 0.4888344 , 0.47915807,\n        0.48750794, 0.50471765, 0.49715284, 0.47733745, 0.5009625 ],\n       [0.4567058 , 0.49945247, 0.45105168, 0.48315364, 0.45869964,\n        0.47980908, 0.5234353 , 0.5042869 , 0.4540868 , 0.51391727],\n       [0.45343727, 0.510322  , 0.43435717, 0.46107298, 0.4682861 ,\n        0.4730136 , 0.51633066, 0.52040464, 0.44292262, 0.49630556],\n       [0.4887304 , 0.49324545, 0.48813435, 0.49154198, 0.48893383,\n        0.49117815, 0.49579227, 0.49375427, 0.48845547, 0.4947891 ],\n       [0.4925535 , 0.49250677, 0.49256492, 0.4925408 , 0.49254224,\n        0.4925322 , 0.49250042, 0.49250078, 0.49255994, 0.49251226],\n       [0.46112987, 0.49859196, 0.45616922, 0.484316  , 0.46287775,\n        0.4813841 , 0.519608  , 0.5028268 , 0.4588325 , 0.51126677],\n       [0.46330965, 0.49918187, 0.45740348, 0.48278195, 0.46619248,\n        0.48160133, 0.5167391 , 0.50359833, 0.46040872, 0.5080241 ],\n       [0.4833541 , 0.49428475, 0.48190442, 0.49013686, 0.4838593 ,\n        0.48927337, 0.500424  , 0.49551785, 0.4826838 , 0.49799263],\n       [0.46528667, 0.49778455, 0.46097958, 0.48540682, 0.46680295,\n        0.48286235, 0.51601475, 0.5014568 , 0.46329233, 0.5087792 ],\n       [0.43992326, 0.5192146 , 0.41107696, 0.44462794, 0.46320468,\n        0.4647528 , 0.5220031 , 0.5340488 , 0.42385516, 0.49247172],\n       [0.42263353, 0.52600586, 0.38731167, 0.43312418, 0.4508979 ,\n        0.45668626, 0.53383076, 0.5447591 , 0.40300736, 0.49646056],\n       [0.47997743, 0.51291823, 0.45508155, 0.45198667, 0.5030629 ,\n        0.47817126, 0.48585016, 0.5230529 , 0.46548972, 0.46565953],\n       [0.43754214, 0.51718366, 0.41146347, 0.44914725, 0.45784196,\n        0.46527308, 0.52650523, 0.53117657, 0.42316905, 0.49869394],\n       [0.48370808, 0.5073922 , 0.4654966 , 0.46288276, 0.5006014 ,\n        0.48213857, 0.4873077 , 0.51477253, 0.47310954, 0.47260332],\n       [0.4611548 , 0.5031129 , 0.45045573, 0.47492254, 0.46851224,\n        0.47890115, 0.5151906 , 0.50947237, 0.45545867, 0.50259626],\n       [0.4537177 , 0.5246331 , 0.41667724, 0.43157393, 0.48643118,\n        0.4652117 , 0.5021047 , 0.5413793 , 0.43250322, 0.46866247],\n       [0.47384125, 0.4961258 , 0.47088426, 0.48764834, 0.47487956,\n        0.48590028, 0.50862753, 0.498642  , 0.47247267, 0.50366735]],\n      dtype=float32)"
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To get original data back (reconstruct)\n",
    "\n",
    "decoded_output"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Encoder-Decoder models will help u encode data & again reconstruct the data using decoder."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}