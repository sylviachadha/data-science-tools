{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# mnist dataset is already heavily preprocessed. Just scale & split\n",
    "# required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "outputs": [],
   "source": [
    "import tensorflow as tf  # for creation & training of nn\n",
    "import tensorflow_datasets as tfds   # to obtain mnist dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Downloading & Preprocessing data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "outputs": [],
   "source": [
    "# Parameters to be used later on-\n",
    "BUFFER_SIZE = 70_000\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 20"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "outputs": [],
   "source": [
    "mnist_dataset, mnist_info = tfds.load(name = 'mnist', with_info=True, as_supervised=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "outputs": [],
   "source": [
    "mnist_train, mnist_test = mnist_dataset['train'],mnist_dataset['test']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "outputs": [],
   "source": [
    "# In ML we like no's that are standardised in some way. So  technique in images is to scale pixel values b/w 0 and 1 which originally would be b/w 0 and 255 for greyscale.\n",
    "# Divide all pixels in dataset by 255, so value will be b/w 0 & 1."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "outputs": [
    {
     "data": {
      "text/plain": "<PrefetchDataset shapes: ((28, 28, 1), ()), types: (tf.uint8, tf.int64)>"
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "outputs": [
    {
     "data": {
      "text/plain": "<PrefetchDataset shapes: ((28, 28, 1), ()), types: (tf.uint8, tf.int64)>"
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "outputs": [],
   "source": [
    "def scale(image, label):\n",
    "    image = tf.cast(image,tf.float32)\n",
    "    image /= 255.\n",
    "\n",
    "    return image, label"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "outputs": [],
   "source": [
    "# Scale every image in train and test dataset\n",
    "train_and_validation_data = mnist_train.map(scale)\n",
    "test_data = mnist_test.map(scale)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "outputs": [],
   "source": [
    "# Validation set is crucial to prevent overfitting using early stopping\n",
    "# Split training set manually to create a validation set (10% of\n",
    "# training set)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "outputs": [
    {
     "data": {
      "text/plain": "60000"
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_info.splits['train'].num_examples"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "outputs": [
    {
     "data": {
      "text/plain": "10000"
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_info.splits['test'].num_examples"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "outputs": [],
   "source": [
    "num_validation_samples = 0.1 * mnist_info.splits['train'].num_examples"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "outputs": [
    {
     "data": {
      "text/plain": "6000.0"
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_validation_samples"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "outputs": [],
   "source": [
    "num_validation_samples = tf.cast(num_validation_samples, tf.int64)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "outputs": [],
   "source": [
    "# we need validation set to contain data with same distribution as training data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "outputs": [],
   "source": [
    "train_and_validation_data = train_and_validation_data.shuffle(BUFFER_SIZE)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "outputs": [],
   "source": [
    "train_data = train_and_validation_data.skip(num_validation_samples)\n",
    "validation_data = train_and_validation_data.take(num_validation_samples)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "outputs": [],
   "source": [
    "# Test Data\n",
    "num_test_samples = mnist_info.splits['test'].num_examples"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "outputs": [],
   "source": [
    "num_test_samples = tf.cast(num_test_samples, tf.int64)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(), dtype=int64, numpy=10000>"
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_test_samples"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "outputs": [],
   "source": [
    "# batch dataset for optimal performance of network\n",
    "# batch size generally recommended in power of 2 (32,64,128) etc\n",
    "\n",
    "# validation & test sets not necessarily be batched as we do not\n",
    "# backward propagate on them however model expects them to be batched to get proper dimensions."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "outputs": [],
   "source": [
    "train_data = train_data.batch(BATCH_SIZE)\n",
    "\n",
    "validation_data = validation_data.batch(num_validation_samples)\n",
    "test_data = test_data.batch(num_test_samples)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Build, Train and Test Network"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "outputs": [],
   "source": [
    "# Define configuration of n/w\n",
    "# Compile model\n",
    "# Fit model on training data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "outputs": [],
   "source": [
    "# keras.sequential refers to fact that layers come 1 after another in sequence. argument for this is a list of all layers\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(50,5,activation='relu', input_shape=(28,28,1)),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "    tf.keras.layers.Conv2D(50,3,activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(10)\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "____________________________________________________________\n",
      " Layer (type)              Output Shape            Param #  \n",
      "============================================================\n",
      " conv2d_8 (Conv2D)         (None, 24, 24, 50)      1300     \n",
      "                                                            \n",
      " max_pooling2d_8 (MaxPooli  (None, 12, 12, 50)     0        \n",
      " ng2D)                                                      \n",
      "                                                            \n",
      " conv2d_9 (Conv2D)         (None, 10, 10, 50)      22550    \n",
      "                                                            \n",
      " max_pooling2d_9 (MaxPooli  (None, 5, 5, 50)       0        \n",
      " ng2D)                                                      \n",
      "                                                            \n",
      " flatten_4 (Flatten)       (None, 1250)            0        \n",
      "                                                            \n",
      " dense_4 (Dense)           (None, 10)              12510    \n",
      "                                                            \n",
      "============================================================\n",
      "Total params: 36,360\n",
      "Trainable params: 36,360\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary(line_length = 60)\n",
    "# 1st dimension is None in output shape cz all data is batched"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "outputs": [],
   "source": [
    "# Above model has 36,360 parameters all of which are trainable.\n",
    "# Trainable parameters r weights of r n/w, the parameters that model is trying to learn. In our model this refers to different no's in the kernel & the final dense layer.\n",
    "# parameters which should not be changed during learning process r non-trainable."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "outputs": [],
   "source": [
    "# Include softmax activation function in the loss function itself instead of dense layer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "outputs": [],
   "source": [
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True)\n",
    "\n",
    "# The from_logits=True attribute inform the loss function that the output values generated by the model are not normalized, a.k.a. logits. In other words, the softmax function has not been applied on them to produce a probability distribution.\n",
    "\n",
    "# if from_logits=False, means the input is a probability and usually you should have some softmax activation in your last layer."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "outputs": [],
   "source": [
    "# Compile model with loss function & optimizer\n",
    "\n",
    "model.compile(optimizer='adam', loss=loss_fn, metrics=['accuracy'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "outputs": [],
   "source": [
    "# To check overfitting, early stopping is the tool.\n",
    "# In tensorflow, early stopping is a callback.\n",
    "# Callbacks are functions that are called at the end of each epoch"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "outputs": [],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor = 'val_loss',\n",
    "    mode = 'auto',\n",
    "    min_delta = 0,\n",
    "    patience = 2,\n",
    "    verbose = 0,\n",
    "    restore_best_weights = True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "422/422 - 19s - loss: 0.2743 - accuracy: 0.9202 - val_loss: 0.0795 - val_accuracy: 0.9753 - 19s/epoch - 45ms/step\n",
      "Epoch 2/20\n",
      "422/422 - 17s - loss: 0.0780 - accuracy: 0.9769 - val_loss: 0.0568 - val_accuracy: 0.9825 - 17s/epoch - 41ms/step\n",
      "Epoch 3/20\n",
      "422/422 - 18s - loss: 0.0552 - accuracy: 0.9832 - val_loss: 0.0377 - val_accuracy: 0.9888 - 18s/epoch - 43ms/step\n",
      "Epoch 4/20\n",
      "422/422 - 18s - loss: 0.0450 - accuracy: 0.9863 - val_loss: 0.0357 - val_accuracy: 0.9875 - 18s/epoch - 43ms/step\n",
      "Epoch 5/20\n",
      "422/422 - 17s - loss: 0.0383 - accuracy: 0.9883 - val_loss: 0.0325 - val_accuracy: 0.9905 - 17s/epoch - 41ms/step\n",
      "Epoch 6/20\n",
      "422/422 - 17s - loss: 0.0321 - accuracy: 0.9903 - val_loss: 0.0240 - val_accuracy: 0.9928 - 17s/epoch - 41ms/step\n",
      "Epoch 7/20\n",
      "422/422 - 17s - loss: 0.0281 - accuracy: 0.9913 - val_loss: 0.0163 - val_accuracy: 0.9947 - 17s/epoch - 41ms/step\n",
      "Epoch 8/20\n",
      "422/422 - 17s - loss: 0.0247 - accuracy: 0.9923 - val_loss: 0.0278 - val_accuracy: 0.9908 - 17s/epoch - 41ms/step\n",
      "Epoch 9/20\n",
      "422/422 - 17s - loss: 0.0217 - accuracy: 0.9930 - val_loss: 0.0132 - val_accuracy: 0.9960 - 17s/epoch - 41ms/step\n",
      "Epoch 10/20\n",
      "422/422 - 17s - loss: 0.0187 - accuracy: 0.9941 - val_loss: 0.0167 - val_accuracy: 0.9945 - 17s/epoch - 41ms/step\n",
      "Epoch 11/20\n",
      "422/422 - 17s - loss: 0.0171 - accuracy: 0.9947 - val_loss: 0.0124 - val_accuracy: 0.9967 - 17s/epoch - 40ms/step\n",
      "Epoch 12/20\n",
      "422/422 - 17s - loss: 0.0140 - accuracy: 0.9958 - val_loss: 0.0116 - val_accuracy: 0.9960 - 17s/epoch - 40ms/step\n",
      "Epoch 13/20\n",
      "422/422 - 17s - loss: 0.0133 - accuracy: 0.9960 - val_loss: 0.0122 - val_accuracy: 0.9953 - 17s/epoch - 41ms/step\n",
      "Epoch 14/20\n",
      "422/422 - 17s - loss: 0.0117 - accuracy: 0.9961 - val_loss: 0.0060 - val_accuracy: 0.9975 - 17s/epoch - 41ms/step\n",
      "Epoch 15/20\n",
      "422/422 - 17s - loss: 0.0100 - accuracy: 0.9967 - val_loss: 0.0096 - val_accuracy: 0.9967 - 17s/epoch - 41ms/step\n",
      "Epoch 16/20\n",
      "422/422 - 18s - loss: 0.0105 - accuracy: 0.9963 - val_loss: 0.0086 - val_accuracy: 0.9972 - 18s/epoch - 42ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x19407ad4ee0>"
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_data,\n",
    "    epochs = NUM_EPOCHS,\n",
    "    callbacks = [early_stopping],\n",
    "    validation_data = validation_data,\n",
    "    verbose = 2 # print info at end of each epoch\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Testing Model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 710ms/step - loss: 0.0303 - accuracy: 0.9917\n"
     ]
    }
   ],
   "source": [
    "# Evaluate network on test dataset\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(test_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss- 0.0303\n",
      "accuracy- 99.17\n"
     ]
    }
   ],
   "source": [
    "# Print result\n",
    "print('loss-',round((test_loss),4))\n",
    "prcnt = ((test_accuracy)*100)\n",
    "print('accuracy-',round((prcnt),2))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "outputs": [],
   "source": [
    "# Plotting images & results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "outputs": [],
   "source": [
    "\n",
    "# Split test data into 2 arrays, having images & labels\n",
    "\n",
    "# .numpy() converts a tensor object into numpy.ndarray\n",
    "\n",
    "for images, labels in test_data.take(1):\n",
    "    images_test = images.numpy()\n",
    "    labels_test = labels.numpy()\n",
    "\n",
    "# Reshape image into 28*28 form, suitable for matplotlib (original: 28*28*1)\n",
    "images_plot = np.reshape(images_test, (10000,28,28))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[[[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]],\n\n        [[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]],\n\n        [[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]],\n\n        ...,\n\n        [[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]],\n\n        [[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]],\n\n        [[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]]],\n\n\n       [[[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]],\n\n        [[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]],\n\n        [[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]],\n\n        ...,\n\n        [[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]],\n\n        [[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]],\n\n        [[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]]],\n\n\n       [[[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]],\n\n        [[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]],\n\n        [[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]],\n\n        ...,\n\n        [[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]],\n\n        [[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]],\n\n        [[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]]],\n\n\n       ...,\n\n\n       [[[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]],\n\n        [[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]],\n\n        [[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]],\n\n        ...,\n\n        [[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]],\n\n        [[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]],\n\n        [[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]]],\n\n\n       [[[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]],\n\n        [[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]],\n\n        [[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]],\n\n        ...,\n\n        [[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]],\n\n        [[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]],\n\n        [[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]]],\n\n\n       [[[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]],\n\n        [[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]],\n\n        [[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]],\n\n        ...,\n\n        [[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]],\n\n        [[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]],\n\n        [[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]]]], dtype=float32)"
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "outputs": [
    {
     "data": {
      "text/plain": "array([2, 0, 4, ..., 8, 0, 5], dtype=int64)"
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[[0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        ...,\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.]],\n\n       [[0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        ...,\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.]],\n\n       [[0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        ...,\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.]],\n\n       ...,\n\n       [[0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        ...,\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.]],\n\n       [[0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        ...,\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.]],\n\n       [[0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        ...,\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.]]], dtype=float32)"
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_plot"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 144x144 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAH4AAAB7CAYAAACy7jQ7AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAEfklEQVR4nO2dzSsFCxyGHSEpSpREUUQoKZINVmShKFkpCysWYk0ppEgoKf+CjQ0LyoKUj7JQWCgsWAglROTz3PX7m+64c8+cL+/77J6cOWfqMX7m8wSCwWCC4CMx2isgooPCk6LwpCg8KQpPisKTkuT2w0AgoH29OCYYDAb+7Wfa4klReFIUnhSFJ0XhSVF4UhSeFIUnReFJUXhSFJ4UhSdF4UlReFIUnhTX8/GxTnJyMvjS0hL4xcUF+OfnJ3hTUxP4+/s7+O3tLfj4+Dj4yckJ+Pf39y9rHDtoiydF4UkJuN1JE+uXXvX394PPzc25vj4QwCuRQr2LaHp6GnxkZATcjpZIo0uvhAOFJ0XhSYnrGb+/vw9eU1Pj+nq/Z7xlZWUFvLe3F/zu7s7Xz/sNzXjhQOFJUXhS4nrGt7W1gc/Pz4Pn5eWB/zbjr66uwN/e3sBLS0s9rV9jYyP4zs6Op+VDRTNeOFB4UhSelLie8ZaCggLwnp4e8L29Pdflj4+PwZ+fn8FHR0fB7bkCy9raGnhHRwf4x8eH6/KhohkvHCg8KQpPyp+a8X6TkZEBvrGxAV5dXe3p/RoaGsB3d3f/34r9RzTjhQOFJ0XhSYnry6u90tnZ6frzzMxM8MHBQfCSkpKQPv/l5SWk5f1EWzwpCk+KwpPyp2Z8d3c3+PDwMHhxcTF4uL+d4+zsDPzy8jKsn+cFbfGkKDwpCk9KXM94O9MnJibAc3NzI7k6Cefn5+AtLS3gT09PkVwdV7TFk6LwpCg8KXE94+1+eqRnuuXw8BA8lvbbLdriSVF4UuL6T729Jcq6JTERf89/fn7A7SFcewtVWlqa6/tXVlaCZ2Vlgd/f37suH0m0xZOi8KQoPClxPePtkyezs7PB7eXRdqZfX1+DDw0Nga+vr4Ovrq6C20ev2Nuo8/PzwTXjRdRReFIUnpS4nvH19fXg5eXl4LW1ta7L28elnZ6eur5+c3MT/LfHq9n/Gbq6usC/vr5clw8n2uJJUXhSFJ6UiN4mXVVVBZ6amgpuZ260qaurA19eXgbPycnx9H728Wv2OITf6DZp4UDhSVF4UsK6H9/X1wc+MDAAbh/rHWmKiorAKyoqwBcXF8G9znT76JTHx0dPy4cTbfGkKDwpCk+KrzM+KQnfrrm52fX1W1tbfn58QmFhIXhZWRl4SkoK+MLCArjfl2dvb2+D22+yjCba4klReFIUnhRfj9Wnp6eDPzw8gNsZNzk5CW7Ph9v97N8eV2avufP61SShYvfb29vbwSM943WsXjhQeFIUnpSIzvhoE+qMtzN8amoK3P6PcnNz4+n9/UYzXjhQeFIUnhRfj9Xbr9M6OjoCt/ePxxr2fPnMzAz47OwseCwde/eKtnhSFJ4UhSclrNfVt7a2go+NjYFHeubb8+P2K0MPDg7AX19fw75O4UT78cKBwpOib5r8w+hPvXCg8KQoPCkKT4rCk6LwpCg8KQpPisKTovCkKDwpCk+KwpOi8KQoPCmu5+PF30VbPCkKT4rCk6LwpCg8KQpPyj8+R1MS3U2xXAAAAABJRU5ErkJggg==\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 3\n"
     ]
    }
   ],
   "source": [
    "# Image to be displayed & tested\n",
    "i = 26\n",
    "\n",
    "# plot image\n",
    "plt.figure(figsize=(2,2))\n",
    "plt.axis('off')\n",
    "plt.imshow(images_plot[i-1], cmap='gray', aspect='auto')\n",
    "plt.show()\n",
    "\n",
    "# print correct label for image\n",
    "print(\"Label: {}\".format(labels_test[i-1]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "outputs": [],
   "source": [
    "# Obtain model's prediction (logits)\n",
    "predictions = model.predict(images_test[i-1:i])\n",
    "\n",
    "# convert prediction into probability\n",
    "probabilities = tf.nn.softmax(predictions).numpy()\n",
    "# convert probabilities to percentages\n",
    "probabilities = probabilities*100"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1.6325680e-13, 1.7127899e-14, 9.2045774e-11, 1.0000000e+02,\n        4.1036546e-18, 4.8041175e-09, 9.6197015e-20, 2.0980051e-11,\n        4.5936375e-08, 2.9962639e-06]], dtype=float32)"
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probabilities"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "outputs": [
    {
     "data": {
      "text/plain": "array([1.6325680e-13, 1.7127899e-14, 9.2045774e-11, 1.0000000e+02,\n       4.1036546e-18, 4.8041175e-09, 9.6197015e-20, 2.0980051e-11,\n       4.5936375e-08, 2.9962639e-06], dtype=float32)"
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probabilities[0]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "outputs": [
    {
     "data": {
      "text/plain": "<BarContainer object of 10 artists>"
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 864x360 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create bar chart to plot probabilities for each class\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.bar(x=[1,2,3,4,5,6,7,8,9,10], height=probabilities[0],\n",
    "        tick_label = [\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 144x144 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAH4AAAB7CAYAAACy7jQ7AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAADpklEQVR4nO2dvyt1cRzHn4OySJT8nCx+DIpBUSIMNqXY/PgDlEmxyC4ZbCaLxSAREyVGi4GNRSYbYvDzWp/3OT1Hl+de557367W9ku5Xr77n0znOPSfIZDJ/wI+i314A/A6EN4XwphDeFMKbQnhTSuJ+GAQB53oFTCaTCf71M3a8KYQ3hfCmEN4UwptCeFMIbwrhTSG8KYQ3hfCmEN4UwptCeFMIbwrhTSG8KYQ3hfCmEN4UwptCeFNib69OOy0tLeJnZ2fi5+fn4l1dXeIfHx+5WVgeYMebQnhTCG+K1Yyvq6sT39zcFH95eRFfWloSL+SZHoYdbwrhTSG8Kame8X19feLz8/PibW1t4mNjY+JbW1u5WVgCYMebQnhTCG9Komd8RUWF+N3dnXgQ6JM+ZmZmxBcXF8VXV1fFm5ubxevr67+xysKEHW8K4U0hvCmJmvFVVVXiy8vL4hsbG+ILCwvijY2N4hMTE+L7+/vig4OD31pnGmDHm0J4UwhvSqJm/PT0tPj4+Lj41NSU+N7envjAwID41dVV7OednJxku8TUwI43hfCmEN6URM347e1t8cfHR/Hwefjl5aX4+/v7jz6/qMhnH/j8pSAQ3hTCmxLEvWky7a8mGR4eFp+dnRUP37NXaG/l5NUkEIHwplgf6svLy8XDl3ibmprEw7d+JR0O9RCB8KYQ3pREXbLNNw8PD+LPz8/i/f394uFLyoUMO94UwptCeFOsz+PDrKysiIcv2XZ2doon/dEonMdDBMKbQnhTUn0e397eLj4yMiJeWVkp3tDQIN7R0SF+fX0tPjk5KX50dPSdZf4K7HhTCG8K4U1J1YwPf+VqfX1dvLi4OPb3Dw8Pxd/e3sSrq6vFw7d3FxLseFMIbwrhTUnVtfrS0lLx8O3TYQ4ODsTv7+/Fw49Lm5ubEy8rKxP/6Ve4/jdcq4cIhDeF8KakasbnmtfXV/HR0VHxnZ2dfC7nS5jxEIHwphDeFGZ8FqytrYn39vaKt7a25nM5X8KMhwiEN4XwpjDjs6C2tlY8/P/47u5u8YuLi5yvKQ5mPEQgvCmEN4UZnwUlJXqL4vHxsXj4EaxDQ0M5X1MczHiIQHhTONT/gJqaGvHT01Pxnp4e8Zubm5yv6W841EMEwptCeFNS9RWqfHN7eyu+u7sr/vT0lM/lZAU73hTCm0J4UziPTzGcx0MEwptCeFMIbwrhTSG8KYQ3JfY8HtILO94UwptCeFMIbwrhTSG8KZ8bve/T/FCHtAAAAABJRU5ErkJggg==\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 7\n"
     ]
    }
   ],
   "source": [
    "# Another test\n",
    "# Image to be displayed & tested\n",
    "i = 34\n",
    "\n",
    "# plot image\n",
    "plt.figure(figsize=(2,2))\n",
    "plt.axis('off')\n",
    "plt.imshow(images_plot[i-1], cmap='gray', aspect='auto')\n",
    "plt.show()\n",
    "\n",
    "# print correct label for image\n",
    "print(\"Label: {}\".format(labels_test[i-1]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "outputs": [],
   "source": [
    "# Obtain model's prediction (logits)\n",
    "predictions = model.predict(images_test[i-1:i])\n",
    "\n",
    "# convert prediction into probability\n",
    "probabilities = tf.nn.softmax(predictions).numpy()\n",
    "# convert probabilities to percentages\n",
    "probabilities = probabilities*100"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1.1116971e-08, 8.9886894e+00, 5.2978821e+01, 1.2327422e+01,\n        6.9462590e+00, 1.0008187e-01, 4.1932258e-06, 1.6649000e+01,\n        2.4038556e-01, 1.7693368e+00]], dtype=float32)"
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probabilities"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "outputs": [
    {
     "data": {
      "text/plain": "<BarContainer object of 10 artists>"
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 864x360 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create bar chart to plot probabilities for each class\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.bar(x=[1,2,3,4,5,6,7,8,9,10], height=probabilities[0],\n",
    "        tick_label = [\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}